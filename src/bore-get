# downloads a given url and extracts to $work
# params: $url, $version
get() {
    [ $# -lt 2 ] && die 'get(): insufficient arguments'
    _url="$1"
    _version="$2"
    _pkgid="${name}${delim}${_version}"
    tmpdir=/tmp/$PKG_MGR_NAME-$$.tmp
    workdir="$work/$name"

    clean
    mkdir -p "$tmpdir" "$sources" "$workdir"
    cd "$sources" || die "get(): could not cd to $sources"

    # NOTE: Downloading via git comes highly unrecommended.
    #       This makes packages depend on git, which is
    #       a rather large dependency for otherwise small programs.
    #       Instead, download a tarball from a commit hash using this format:
    #       version=<SHA_HASH>
    #       source=http://github.com/<GITHUB_USER>/$name/archive/$version.tar.gz
    if [ "$_version" = git ] ; then

        if [ ! -d "$_pkgid" ] ; then
            msg "cloning $_url..."
            git clone -q --progress --depth 1 "$_url" "$tmpdir" || \
                die "get(): could not clone $_url"
            mv -f "$tmpdir"/* "$workdir"
            $keep_tarballs && cp -rf "$workdir" "$sources"/"$_pkgid"
        else
            if [ -d "$workdir" ] ; then
                sanity_check && rm -rf "$workdir"
            fi
            cp -rf "$sources"/"$_pkgid" "$workdir"
        fi

    else # we are downloading with curl

        if [ ! -f "$_pkgid" ] ; then
            msg "downloading $_url..."
            # note: curl has problems with many ${delim}s, so as a workaround 
            #       we perform this temporary file and rename it
            curl -q -L -C - -# --url "$_url" -o "$name"-download ||
                die "get(): could not download $name"
            mv -f "$name"-download "$_pkgid"
        fi
        cp -f "$_pkgid" "$tmpdir"

        case $(file "$tmpdir"/*) in
            *tgz*) ext=tgz   ;;
            *'gzip comp'*)  ext=gz    ;;
            *'bzip2 comp'*) ext=bz2   ;;
            *'XZ comp'*)    ext=xz    ;;
            *) die "get(): could not discern compression type of $name"
        esac

        # decompressors bug out if no extension...
        mv -f "$tmpdir"/* "$tmpdir/${name}.${ext}"

        msg "extracting $name"...
        case $ext in
            xz)     xz      -d "$tmpdir"/* ;;
            gz|tgz) gunzip  -d "$tmpdir"/* ;;
            bz2)    bunzip2 -d "$tmpdir"/* ;;
            *) die "get(): unknown compression algorithm"
        esac || die "get(): failed to decompress $name"

        if file "$tmpdir"/* | grep 'tar archive' > /dev/null ; then
            ext=tar.${ext}
            mv "$tmpdir"/* "$tmpdir/${name}".tar
            tar -xf "$tmpdir/${name}.tar" -C "$tmpdir"/ || 
                die "get(): tar could not extract $_pkgid.$ext"       
        fi

        ! $keep_tarballs && rm -f "$sources"/"$_pkgid" 

        {
            mv -f "$tmpdir"/*/* "$workdir"
            find "$tmpdir" -name ".*" ! -name . | while read -r file ; do
                mv -f "$file" "$workdir"
            done
        } || die "get(): failed to move unpacked tarball"
    fi

    # copy all port's files, except its pkgfile -- (ex: patches)
    find "$ports/$name"/* ! -name pkgfile | while read -r file ; do
        cp -f "$file" "$workdir"
    done

    rm -rf "${tmpdir:?}"

    unset _url _version _pkgid ext tmpdir file workdir
}
# vi:syntax=sh
# shellcheck shell=sh
